model, flops,layers,headings,inference_time,accuracy,loss
google/bert_uncased_L-2_H-128_A-2,10401318,2,128,1.861904,0.703768,0.600383
google/bert_uncased_L-2_H-256_A-4,25652262,2,256,1.904819,0.735652,0.587508
google/bert_uncased_L-2_H-512_A-8,70703142,2,512,1.887417,0.745507,0.768554
google/bert_uncased_L-2_H-768_A-12,135152678,2,768,2.228185,0.743188,1.015138
google/bert_uncased_L-4_H-128_A-2,12787902,4,128,2.315212,0.725217,0.578155
google/bert_uncased_L-4_H-256_A-4,35143998,4,256,2.339513,0.757101,0.571577
google/bert_uncased_L-4_H-512_A-8,108560958,4,512,2.401021,0.773913,0.762311
google/bert_uncased_L-4_H-768_A-12,220250942,4,768,3.308602,0.80058,0.886631
google/bert_uncased_L-6_H-128_A-2,15174486,6,128,2.73642,0.725217,0.571712
google/bert_uncased_L-6_H-256_A-4,44635734,6,256,2.792287,0.778551,0.49516
google/bert_uncased_L-6_H-512_A-8,146418774,6,512,2.900288,0.802899,0.833994
google/bert_uncased_L-6_H-768_A-12,305349206,6,768,4.505849,0.82087,0.843674
google/bert_uncased_L-8_H-128_A-2,17561070,8,128,3.147497,0.744348,0.556068
google/bert_uncased_L-8_H-256_A-4,54127470,8,256,3.275725,0.768116,0.569804
google/bert_uncased_L-8_H-512_A-8,184276590,8,512,3.294029,0.818551,0.839448
google/bert_uncased_L-8_H-768_A-12,390447470,8,768,5.694755,0.823768,0.934178
google/bert_uncased_L-10_H-128_A-2,19947654,10,128,3.818855,0.761739,0.505063
google/bert_uncased_L-10_H-256_A-4,63619206,10,256,3.670695,0.77971,0.594048
google/bert_uncased_L-10_H-512_A-8,222134406,10,512,3.996694,0.827826,0.776526
google/bert_uncased_L-10_H-768_A-12,475545734,10,768,6.964894,0.834783,0.824279
